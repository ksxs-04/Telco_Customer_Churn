{
 "cells": [
  {
   "cell_type": "code",
   "id": "313203d96234dcb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:12.871427Z",
     "start_time": "2025-12-11T13:31:12.860696Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:15.159480Z",
     "start_time": "2025-12-11T13:31:15.079995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "df.shape"
   ],
   "id": "6e4f04d3d44fce74",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:17.081832Z",
     "start_time": "2025-12-11T13:31:17.062900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Converting TotalCharges to numeric...\")\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "nan_count = df['TotalCharges'].isnull().sum()\n",
    "print(f\"   Found {nan_count} missing values\")"
   ],
   "id": "7cb8ccd071d491fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting TotalCharges to numeric...\n",
      "   Found 11 missing values\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:19.148984Z",
     "start_time": "2025-12-11T13:31:19.122644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill missing values with median\n",
    "df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)\n",
    "print(f\"   Filled with median: {df['TotalCharges'].median():.2f}\")\n",
    "df = df.drop('customerID', axis=1)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "print(\"   Encoded target: Yes→1, No→0\")\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']"
   ],
   "id": "e49f3bd236fb3bdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Filled with median: 1397.47\n",
      "   Encoded target: Yes→1, No→0\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:21.392908Z",
     "start_time": "2025-12-11T13:31:21.335782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert categorical variables to numeric codes (simple approach)\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ],
   "id": "f70920b4d9f8572",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7043, 19)\n",
      "Target distribution: {0: 5174, 1: 1869}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:25.614195Z",
     "start_time": "2025-12-11T13:31:25.582208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SPLIT ONCE AND KEEP IT CONSISTENT\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"Features: {X_train.shape[1]}\")\n",
    "print(f\"Original training distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Original test distribution: {y_test.value_counts().to_dict()}\")"
   ],
   "id": "1f9a1cfbaf5752f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 5634 samples\n",
      "Test set: 1409 samples\n",
      "Features: 19\n",
      "Original training distribution: {0: 4139, 1: 1495}\n",
      "Original test distribution: {0: 1035, 1: 374}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:31:43.411406Z",
     "start_time": "2025-12-11T13:31:43.363669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============ BASELINE MODELS ============\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE DECISION TREE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Baseline fixed model\n",
    "model_dt = DecisionTreeClassifier(criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_baseline = model_dt.predict(X_test)\n",
    "\n",
    "print(f\"Baseline Accuracy: {accuracy_score(y_test, y_pred_baseline):.4f}\")\n",
    "print(f\"Baseline Model Score: {model_dt.score(X_test, y_test):.4f}\")"
   ],
   "id": "e5a67d709490675f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "BASELINE DECISION TREE\n",
      "==================================================\n",
      "Baseline Accuracy: 0.7821\n",
      "Baseline Model Score: 0.7821\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:32:11.712706Z",
     "start_time": "2025-12-11T13:31:48.500708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============ BASELINE WITH HYPERPARAMETER TUNING ============\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BASELINE MODEL - HYPERPARAMETER TUNING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create and fit tuned model\n",
    "baseline_tuned = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=100),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "baseline_tuned.fit(X_train, y_train)\n",
    "y_pred_baseline_tuned = baseline_tuned.predict(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {baseline_tuned.best_params_}\")\n",
    "print(f\"Tuned Accuracy: {accuracy_score(y_test, y_pred_baseline_tuned):.4f}\")"
   ],
   "id": "56a88514d0874819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "BASELINE MODEL - HYPERPARAMETER TUNING\n",
      "==================================================\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "Tuned Accuracy: 0.7850\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:32:15.237105Z",
     "start_time": "2025-12-11T13:32:14.886360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============ SMOTEENN MODELS WITH PIPELINE ============\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SMOTEENN MODELS (WITH PIPELINE)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline\n",
    "smote_pipeline = Pipeline([\n",
    "    ('smoteenn', SMOTEENN(random_state=42)),\n",
    "    ('classifier', DecisionTreeClassifier(\n",
    "        criterion='gini',\n",
    "        random_state=100,\n",
    "        max_depth=6,\n",
    "        min_samples_leaf=8\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train with ONE line (pipeline handles SMOTEENN internally)\n",
    "smote_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict with ONE line\n",
    "y_pred_smote = smote_pipeline.predict(X_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_smote):.4f}\")\n",
    "\n",
    "# Bonus: You can still see what SMOTEENN did\n",
    "print(f\"\\nPipeline steps: {[step[0] for step in smote_pipeline.steps]}\")"
   ],
   "id": "51ed9e0395faff13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "SMOTEENN MODELS (WITH PIPELINE)\n",
      "==================================================\n",
      "Test Accuracy: 0.6977\n",
      "\n",
      "Pipeline steps: ['smoteenn', 'classifier']\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:40:45.152544Z",
     "start_time": "2025-12-11T13:32:20.238547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============ SMOTEENN TUNED MODEL WITH PIPELINE ============\n",
    "print(\"\\n--- SMOTEENN Tuned Model (WITH PIPELINE - CORRECT) ---\")\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Create pipeline first\n",
    "smote_tuning_pipeline = Pipeline([\n",
    "    ('smoteenn', SMOTEENN(random_state=42)),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=100))\n",
    "])\n",
    "\n",
    "# Parameter grid for ENTIRE pipeline\n",
    "param_grid_smote = {\n",
    "    'smoteenn__sampling_strategy': [0.5, 0.75, 1.0],  # Control SMOTEENN balance\n",
    "    'classifier__criterion': ['gini', 'entropy'],\n",
    "    'classifier__max_depth': [4, 6, 8, 10, 12],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4, 8],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# GridSearchCV with pipeline\n",
    "smote_tuned = GridSearchCV(\n",
    "    smote_tuning_pipeline,  # Use pipeline instead of just model\n",
    "    param_grid_smote,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Fit on ORIGINAL X_train, y_train (not resampled!)\n",
    "smote_tuned.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {smote_tuned.best_params_}\")\n",
    "print(f\"Best CV Score: {smote_tuned.best_score_:.4f}\")\n",
    "\n",
    "# Predict with best pipeline\n",
    "y_pred_smote_tuned = smote_tuned.predict(X_test)\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_smote_tuned):.4f}\")\n",
    "\n",
    "# Predict on the ORIGINAL test set\n",
    "y_pred_smote_tuned = smote_tuned.predict(X_test)\n",
    "\n",
    "print(f\"Best Parameters: {smote_tuned.best_params_}\")\n",
    "print(f\"Best CV Score: {smote_tuned.best_score_:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_smote_tuned):.4f}\")"
   ],
   "id": "503ac9ce130250a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SMOTEENN Tuned Model (WITH PIPELINE - CORRECT) ---\n",
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 12, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'smoteenn__sampling_strategy': 0.5}\n",
      "Best CV Score: 0.7865\n",
      "Test Accuracy: 0.7736\n",
      "Best Parameters: {'classifier__criterion': 'gini', 'classifier__max_depth': 12, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 10, 'smoteenn__sampling_strategy': 0.5}\n",
      "Best CV Score: 0.7865\n",
      "Test Accuracy: 0.7736\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T13:40:45.796148Z",
     "start_time": "2025-12-11T13:40:45.505980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ============ FINAL COMPARISON ============\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL COMPARISON OF ALL MODELS (ALL EVALUATED ON ORIGINAL TEST SET)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prepare results\n",
    "results = []\n",
    "\n",
    "# Baseline fixed\n",
    "acc1 = accuracy_score(y_test, y_pred_baseline)\n",
    "prec1 = metrics.precision_score(y_test, y_pred_baseline, pos_label=1, zero_division=0)\n",
    "rec1 = metrics.recall_score(y_test, y_pred_baseline, pos_label=1, zero_division=0)\n",
    "f1_1 = metrics.f1_score(y_test, y_pred_baseline, pos_label=1, zero_division=0)\n",
    "results.append((\"Baseline (Fixed)\", acc1, prec1, rec1, f1_1))\n",
    "\n",
    "# Baseline tuned\n",
    "acc2 = accuracy_score(y_test, y_pred_baseline_tuned)\n",
    "prec2 = metrics.precision_score(y_test, y_pred_baseline_tuned, pos_label=1, zero_division=0)\n",
    "rec2 = metrics.recall_score(y_test, y_pred_baseline_tuned, pos_label=1, zero_division=0)\n",
    "f1_2 = metrics.f1_score(y_test, y_pred_baseline_tuned, pos_label=1, zero_division=0)\n",
    "results.append((\"Baseline (Tuned)\", acc2, prec2, rec2, f1_2))\n",
    "\n",
    "# SMOTEENN fixed\n",
    "acc3 = accuracy_score(y_test, y_pred_smote)\n",
    "prec3 = metrics.precision_score(y_test, y_pred_smote, pos_label=1, zero_division=0)\n",
    "rec3 = metrics.recall_score(y_test, y_pred_smote, pos_label=1, zero_division=0)\n",
    "f1_3 = metrics.f1_score(y_test, y_pred_smote, pos_label=1, zero_division=0)\n",
    "results.append((\"SMOTEENN (Fixed)\", acc3, prec3, rec3, f1_3))\n",
    "\n",
    "# SMOTEENN tuned\n",
    "acc4 = accuracy_score(y_test, y_pred_smote_tuned)\n",
    "prec4 = metrics.precision_score(y_test, y_pred_smote_tuned, pos_label=1, zero_division=0)\n",
    "rec4 = metrics.recall_score(y_test, y_pred_smote_tuned, pos_label=1, zero_division=0)\n",
    "f1_4 = metrics.f1_score(y_test, y_pred_smote_tuned, pos_label=1, zero_division=0)\n",
    "results.append((\"SMOTEENN (Tuned)\", acc4, prec4, rec4, f1_4))\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n{'Model':<25} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for name, acc, prec, rec, f1 in results:\n",
    "    print(f\"{name:<25} {acc:<10.4f} {prec:<10.4f} {rec:<10.4f} {f1:<10.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_acc = max([acc for _, acc, _, _, _ in results])\n",
    "best_models = [name for name, acc, _, _, _ in results if acc == best_acc]\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(f\"BEST MODEL(S) BY ACCURACY: {', '.join(best_models)} (Accuracy: {best_acc:.4f})\")\n",
    "\n",
    "# Additional: Find best by F1-score (often better for imbalanced data)\n",
    "best_f1 = max([f1 for _, _, _, _, f1 in results])\n",
    "best_f1_models = [name for name, _, _, _, f1 in results if f1 == best_f1]\n",
    "print(f\"BEST MODEL(S) BY F1-SCORE: {', '.join(best_f1_models)} (F1: {best_f1:.4f})\")\n",
    "\n",
    "# ============ DETAILED REPORTS ============\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "reports = [\n",
    "    (\"Baseline (Fixed)\", y_test, y_pred_baseline),\n",
    "    (\"Baseline (Tuned)\", y_test, y_pred_baseline_tuned),\n",
    "    (\"SMOTEENN (Fixed)\", y_test, y_pred_smote),\n",
    "    (\"SMOTEENN (Tuned)\", y_test, y_pred_smote_tuned)\n",
    "]\n",
    "\n",
    "for name, y_true, y_pred in reports:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(classification_report(y_true, y_pred, labels=[0, 1], target_names=['No Churn', 'Churn']))\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL COMPARISON OF ALL MODELS (ALL EVALUATED ON ORIGINAL TEST SET)\n",
      "======================================================================\n",
      "\n",
      "Model                     Accuracy   Precision  Recall     F1-Score  \n",
      "-----------------------------------------------------------------\n",
      "Baseline (Fixed)          0.7821     0.5971     0.5508     0.5730    \n",
      "Baseline (Tuned)          0.7850     0.6035     0.5535     0.5774    \n",
      "SMOTEENN (Fixed)          0.6977     0.4622     0.8503     0.5989    \n",
      "SMOTEENN (Tuned)          0.7736     0.5733     0.5749     0.5741    \n",
      "\n",
      "======================================================================\n",
      "BEST MODEL(S) BY ACCURACY: Baseline (Tuned) (Accuracy: 0.7850)\n",
      "BEST MODEL(S) BY F1-SCORE: SMOTEENN (Fixed) (F1: 0.5989)\n",
      "\n",
      "======================================================================\n",
      "DETAILED CLASSIFICATION REPORTS\n",
      "======================================================================\n",
      "\n",
      "Baseline (Fixed):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.84      0.87      0.85      1035\n",
      "       Churn       0.60      0.55      0.57       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.71      0.71      1409\n",
      "weighted avg       0.78      0.78      0.78      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[896 139]\n",
      " [168 206]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Baseline (Tuned):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.84      0.87      0.86      1035\n",
      "       Churn       0.60      0.55      0.58       374\n",
      "\n",
      "    accuracy                           0.78      1409\n",
      "   macro avg       0.72      0.71      0.72      1409\n",
      "weighted avg       0.78      0.78      0.78      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[899 136]\n",
      " [167 207]]\n",
      "--------------------------------------------------\n",
      "\n",
      "SMOTEENN (Fixed):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.92      0.64      0.76      1035\n",
      "       Churn       0.46      0.85      0.60       374\n",
      "\n",
      "    accuracy                           0.70      1409\n",
      "   macro avg       0.69      0.75      0.68      1409\n",
      "weighted avg       0.80      0.70      0.72      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[665 370]\n",
      " [ 56 318]]\n",
      "--------------------------------------------------\n",
      "\n",
      "SMOTEENN (Tuned):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.85      0.85      0.85      1035\n",
      "       Churn       0.57      0.57      0.57       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.71      0.71      1409\n",
      "weighted avg       0.77      0.77      0.77      1409\n",
      "\n",
      "Confusion Matrix:\n",
      "[[875 160]\n",
      " [159 215]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
